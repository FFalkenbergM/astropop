{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Your Own Reduction Scrypt (photometry)\n",
    "\n",
    "*Work in Progress*\n",
    "\n",
    "ASTROPOP is not a reduction script by itself, but a library containing (almost) everything you need to create your reduction script by yourself.\n",
    "\n",
    "In this guide we will follow a standard reduction procedure using the ASTROPOP modules and you can follow it to perform your own reduction.\n",
    "\n",
    "If you want to use this notebook directly in your Jupyter, you can download it in [this link](https://raw.githubusercontent.com/sparc4-dev/astropop/main/docs/ipynb/diy_reduction_script.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize Your Data\n",
    "\n",
    "The first step is to organize your data. *Do not forget to backup all the raw data before start your reduction!*\n",
    "\n",
    "Here we will perform a reduction using just bias and flatfield corrections, in a single band. No dark frame subtraction will be used, so we do not have to set it.\n",
    "\n",
    "First, we will have to create the lists containing the image names we need. You can do it manually, using [glob](https://docs.python.org/3/library/glob.html) package, or the built-in file organizer of ASTROPOP. This last option allow filtering using header keys, but may be slow and memory consuming for very large sets (with thousands of images). For didatic reasons, we will to it with ASTROPOP file organizer.\n",
    "\n",
    "Is convenient to set now some directory names for raw, reduced and temporary files, as in the code bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from astropy import units as u\n",
    "\n",
    "# astropop used modules\n",
    "from astropop.image import imcombine, processing, imarith\n",
    "from astropop.framedata import read_framedata\n",
    "from astropop.logger import logger\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "# Directories where we will storefiles\n",
    "base_dir = os.path.expanduser('~/astropop-tutorial/photometry-example')\n",
    "raw_dir = os.path.join(base_dir, 'raw')  # Directory containing the rawdata\n",
    "reduced_dir = os.path.join(base_dir, 'reduced')  # Directory to store processed data\n",
    "tmp_dir = os.path.join(base_dir, 'tmp')  # Directory to store temporary files\n",
    "\n",
    "# create the dir if not exists\n",
    "os.makedirs(raw_dir, exist_ok=True)  \n",
    "os.makedirs(reduced_dir, exist_ok=True)\n",
    "os.makedirs(tmp_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will a set of images of HD5980 star taken in Observat√≥rio do Pico dos Dias (OPD/LNA) and available in [github/sparc4-dev/astropop-data](https://github.com/sparc4-dev/astropop-data) repository.\n",
    "\n",
    "To download these data in the raw folder, follow the script bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the data\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "with urllib.request.urlopen('https://raw.githubusercontent.com/sparc4-dev/astropop-data/main/raw_images/opd_ixon_bc_hd5980/filelist.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        url = line.decode('UTF-8')\n",
    "        filename = os.path.join(raw_dir, url.split('/')[-1].split('?')[0])\n",
    "        urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `astropop.file_collection.FitsFileGroup` we will create a dynamic library of fits files. This library allow iterate over its files, filter by header keywords, access file names or direct access a given index. In this case, we will access only the file names via `FitsFileGroup.files` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropop.file_collection import FitsFileGroup\n",
    "\n",
    "main_fg = FitsFileGroup(location=raw_dir, fits_ext=['.fits'], ext=0)\n",
    "\n",
    "print(f'Total files: {len(main_fg)}')\n",
    "\n",
    "# Filter files by header keywords\n",
    "bias_fg = main_fg.filtered({'obstype': 'BIAS'})  # OBSTYPE='BIAS'\n",
    "print(f'Bias files: {len(bias_fg)}')\n",
    "print(bias_fg.files)\n",
    "flat_fg = main_fg.filtered({'obstype': 'FLAT'})  # OBSTYPE='FLAT'\n",
    "print(f'Flat files: {len(flat_fg)}')\n",
    "print(flat_fg.files)\n",
    "star_fg = main_fg.filtered({'obstype': 'SCIENCE', 'object': 'HD5980'})  # OBSTYPE='SCIENCE' and OBJECT='HD5980'\n",
    "print(f'Star files: {len(star_fg)}')\n",
    "print(star_fg.files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master Calibration Frames\n",
    "\n",
    "Before process the science images, we need to create the `master_bias` and `master_flat` calibration frames.\n",
    "\n",
    "### Master Bias\n",
    "\n",
    "Bias files will be corrected by gain, cosmic removal and after they will be median combined to generate the `master_bias` file.\n",
    "\n",
    "The first step is to read the fits files to `FrameData` instances. `use_memmap_backend` feature will be used to save RAM. `FitsFileGroup`s already have a feature to read and iterate over the `FrameData` created instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_frames = list(bias_fg.framedata(unit='adu', use_memmap_backend=True))\n",
    "\n",
    "# lest extract gain from the first image\n",
    "gain = float(bias_frames[0].header['GAIN'])*u.electron/u.adu\n",
    "print('gain:', gain)\n",
    "\n",
    "# Perform calibrations\n",
    "for i, frame in enumerate(bias_frames):\n",
    "    print(f'processing frame {i+1} from {len(bias_frames)}')\n",
    "    processing.cosmics_lacosmic(frame, inplace=True)\n",
    "    processing.gain_correct(frame, gain, inplace=True)\n",
    "\n",
    "# combine\n",
    "master_bias = imcombine(bias_frames, method='median')\n",
    "\n",
    "# save to disk\n",
    "mbias_name = os.path.join(reduced_dir, 'master_bias.fits')\n",
    "master_bias.write(mbias_name, overwrite=True, no_fits_standard_units=True)\n",
    "master_bias.meta['astropop master_type'] = 'bias'\n",
    "print('master_bias statistics', master_bias.statistics())\n",
    "\n",
    "del bias_frames  # remove tmp frames from memory and disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master Flat\n",
    "\n",
    "In addition to cosmic/gain correction, flat frames must be subtracted by the master bias and normalized after the combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_frames = list(flat_fg.framedata(unit='adu', use_memmap_backend=True))\n",
    "\n",
    "for i, frame in enumerate(flat_frames):\n",
    "    print(f'processing frame {i+1} from {len(flat_frames)}')\n",
    "    processing.cosmics_lacosmic(frame, inplace=True)\n",
    "    processing.gain_correct(frame, gain, inplace=True)\n",
    "    processing.subtract_bias(frame, master_bias, inplace=True)\n",
    "\n",
    "# combine and normalize\n",
    "master_flat = imcombine(flat_frames, method='median')\n",
    "mean_value = master_flat.mean()\n",
    "print('flat mean value:', mean_value)\n",
    "master_flat = imarith(master_flat, mean_value, '/')\n",
    "master_bias.meta['astropop master_type'] = 'flat'\n",
    "\n",
    "# save to disk\n",
    "mflat_name = os.path.join(reduced_dir, 'master_flat.fits')\n",
    "master_flat.write(mflat_name, overwrite=True)\n",
    "print('master_flat statistics', master_flat.statistics())\n",
    "\n",
    "del flat_frames  # remove tmp frames from memory and disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic CCD Image Processing\n",
    "\n",
    "Now, with our master images created, its time to performe the processing of our science images.\n",
    "\n",
    "The steps are:\n",
    "- cosmic ray removal\n",
    "- gain correct\n",
    "- master_bias subtraction\n",
    "- division by normalized flat\n",
    "\n",
    "We already have the master images loaded into the memory. But, considering you have the master frames already created, lets load them from the disk using `read_framedata` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_bias = read_framedata(mbias_name)\n",
    "print('bias: ', master_bias.statistics())\n",
    "master_flat = read_framedata(mflat_name)\n",
    "print('flat:', master_flat.statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the frames, process them and save individual files calibrated files to disk\n",
    "star_frames = list(star_fg.framedata(unit='adu', use_memmap_backend=True))\n",
    "\n",
    "for i, frame in enumerate(star_frames):\n",
    "    print(f'processing frame {i+1} from {len(star_frames)}')\n",
    "    processing.cosmics_lacosmic(frame, inplace=True)\n",
    "    processing.gain_correct(frame, gain, inplace=True)\n",
    "    processing.subtract_bias(frame, master_bias, inplace=True)\n",
    "    processing.flat_correct(frame, master_flat, inplace=True)\n",
    "    \n",
    "for frame, name in zip(star_frames, star_fg.files):\n",
    "    basename = os.path.basename(name)\n",
    "    frame.write(os.path.join(reduced_dir, basename), overwrite=True, no_fits_standard_units=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align and Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Detection and Photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photometry Calibration with Online Catalogs"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "162041a95dc008afa7a541b7cce9944c08c53eb30e22b146ef152cba0893111e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
